<!DOCTYPE html>
<html lang="es">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Galería IA con Filtros</title>
  <script src="/assets/tailwind.js"></script>
  <link href="/assets/fonts.css" rel="stylesheet">
  <style>
    body {
      font-family: 'Orbitron', sans-serif;
      background-color: #0f172a;
      color: white;
    }
    .mini-button {
      width: 1.5em;
      height: 1.5em;
      border-radius: 3px;
      border: 1px solid #000;
      cursor: pointer;
      transition: transform 0.2s ease-in-out;
    }
    .mini-button:hover {
      transform: scale(1.2);
    }

    .mini-buttons-container {
  display: flex;
  flex-direction: row;
  flex-wrap: nowrap;
  overflow-x: auto;
  gap: 8px;
  padding-top: 10px;
  margin-top: 10px;
}
</style>
</head>
<body>

  <!-- Navbar -->
  <nav class="bg-gradient-to-r from-purple-800 via-indigo-800 to-blue-800 p-4 text-center text-sm md:text-base font-semibold uppercase tracking-wider">
    <a href="../../a.html" class="mx-3 hover:text-yellow-400">Inicio</a>
  </nav>

  <!-- Encabezado con imagen y franja -->
  <section class="max-w-7xl mx-auto px-6 mb-10">
    <div class="relative flex items-center justify-between">
      <!-- Imagen circular -->
      <div class="absolute -left-4 md:-left-10 z-20">
  <video autoplay muted loop
         class="w-40 h-40 md:w-52 md:h-52 object-cover rounded-full border-4 border-yellow-400 shadow-2xl">
    <source src="/ruta/ia_voces.mp4" type="video/mp4">
  </video>
      </div>

      <!-- Franja con título -->
      <div class="w-full bg-purple-800 h-28 md:h-32 rounded-xl flex items-center pl-48 pr-6 z-10 shadow-lg">
        <h2 class="text-2xl md:text-4xl text-yellow-400 font-bold ml-auto">IA Voces</h2>
      </div>
    </div>

    <!-- Nueva barra de navegación específica de IA -->
    <nav class="flex justify-end mt-4 space-x-6 text-white text-sm md:text-base">
        <a href="origenes-voz.html" class="hover:text-yellow-400 transition" style="font-size: 10px;">Orígenes IA Voz</a>
        <a href="como-funciona-voz.html" class="hover:text-yellow-400 transition" style="font-size: 10px;">Cómo funciona</a>
        <a href="control-voz.html" class="hover:text-yellow-400 transition" style="font-size: 10px;">Control creativo</a>
        <a href="voz-sin-censura.html" class="hover:text-yellow-400 transition" style="font-size: 10px;">IA sin censura</a>
        <a href="tutorial-voz.html" class="hover:text-yellow-400 transition" style="font-size: 10px;">Tutorial Voz IA</a>
        <a href="top10-voz.html" class="hover:text-yellow-400 transition" style="font-size: 10px;">Top 10 IA Voz</a>
        <a href="galeria-voz.html" class="hover:text-yellow-400 transition" style="font-size: 10px;">Galería</a>
      </nav>
  </section>

<!-- Contenido -->
<main class="max-w-4xl mx-auto px-6 leading-relaxed text-justify">
    <h3 class="text-yellow-400 text-xl font-bold mb-4">¿Cómo empezó la Inteligencia Artificial de voz?</h3>
    
    <p class="mb-4">
      La generación artificial de voces humanas comenzó mucho antes de que existiera la “IA” como la conocemos hoy. En los años 60, los primeros sintetizadores de voz eran mecánicos o electrónicos. Uno de los más conocidos, <strong>Voder</strong> de Bell Labs (1939), producía sonidos controlados manualmente.
    </p>
  
    <h4 class="text-yellow-300 text-lg font-bold mb-2">Del TTS clásico a la IA moderna</h4>
    <p class="mb-4">
      En los años 80 y 90, surgieron los sistemas <strong>Text-to-Speech (TTS)</strong> basados en reglas gramaticales y concatenación de fonemas grabados. Aunque útiles, sus resultados eran robóticos. Algunos ejemplos históricos: el sintetizador de voz de Stephen Hawking, y Microsoft Sam.
    </p>
  
    <h4 class="text-yellow-300 text-lg font-bold mb-2">Llega el Deep Learning</h4>
    <p class="mb-4">
      Con la revolución del <strong>deep learning</strong>, las voces generadas empezaron a sonar humanas. Modelos como <strong>WaveNet</strong> (DeepMind, 2016) permitieron un salto de calidad. En lugar de unir sonidos pregrabados, estas IAs aprendieron a generar audio desde cero, fonema a fonema.
    </p>
  
    <h4 class="text-yellow-300 text-lg font-bold mb-2">Clonación y canto: los siguientes pasos</h4>
    <p class="mb-4">
      En la actualidad, existen modelos capaces de clonar voces con solo unos segundos de audio. Herramientas como <strong>ElevenLabs</strong>, <strong>XTTS</strong> o <strong>DiffSinger</strong> permiten doblar películas, cantar canciones y crear narraciones completas con voces sintéticas personalizadas.
    </p>
  
    <p class="mb-4">
      Además, las IAs de canto como <strong>SVC</strong> (Soft Voice Conversion) y <strong>DiffSinger</strong> han abierto el camino para que cualquier persona pueda componer música vocal sin tener que cantar, solo escribiendo una melodía.
    </p>
  
    <div class="mt-8 text-sm text-center text-gray-400 italic">
      De voces robóticas a cantantes virtuales con emoción humana: la IA ha afinado su oído y su garganta.
    </div>
  </main>
  
  <!-- Footer -->
  <footer class="text-center text-xs text-gray-400 mt-10 mb-4">
    &copy; 2025 Proyecto IA de Voz - Todos los derechos reservados.
  </footer>
  
